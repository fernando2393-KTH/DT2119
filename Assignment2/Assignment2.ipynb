{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## <p style=\"text-align: center\">DT2119 Lab2: Hidden Markov Models with Gaussian Emissions\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following packages and files will be used to accomplish the different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lab2_tools import *\n",
    "from prondict import prondict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are all the implemented functions which will be used\n",
    "to accomplish the different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def concatTwoHMMs(hmm1, hmm2):\n",
    "    \"\"\" Concatenates 2 HMM models\n",
    "\n",
    "    Args:\n",
    "       hmm1, hmm2: two dictionaries with the following keys:\n",
    "           - name: phonetic or word symbol corresponding to the model\n",
    "           - startprob: M+1 array with priori probability of state\n",
    "           - transmat: (M+1)x(M+1) transition matrix\n",
    "           - means: MxD array of mean vectors\n",
    "           - covars: MxD array of variances\n",
    "\n",
    "    D is the dimension of the feature vectors\n",
    "    M is the number of emitting states in each HMM model (could be different for each)\n",
    "\n",
    "    Output\n",
    "       dictionary with the same keys as the input but concatenated models:\n",
    "          startprob: K+1 array with priori probability of state\n",
    "          transmat: (K+1)x(K+1) transition matrix\n",
    "             means: KxD array of mean vectors\n",
    "            covars: KxD array of variances\n",
    "\n",
    "    K is the sum of the number of emitting states from the input models\n",
    "   \n",
    "    Example:\n",
    "       twoHMMs = concatHMMs(phoneHMMs['sil'], phoneHMMs['ow'])\n",
    "\n",
    "    See also: the concatenating_hmms.pdf document in the lab package\n",
    "    \"\"\"\n",
    "\n",
    "    concat_hmm = {}\n",
    "    startprob = np.zeros(hmm1['startprob'].shape[0] + hmm2['startprob'].shape[0] - 1)\n",
    "    for i in range(startprob.shape[0]):\n",
    "        if i < hmm1['startprob'].shape[0] - 1:\n",
    "            startprob[i] = hmm1['startprob'][i]\n",
    "        else:\n",
    "            startprob[i] = hmm1['startprob'][-1] * hmm2['startprob'][i - (hmm1['startprob'].shape[0] - 1)]\n",
    "\n",
    "    transmat = np.zeros((startprob.shape[0], startprob.shape[0]))\n",
    "    for i in range(transmat.shape[0] - 1):\n",
    "        for j in range(transmat.shape[1]):\n",
    "            if i < hmm1['transmat'].shape[0] - 1 and j < hmm1['transmat'].shape[1] - 1:  # Copy of hmm1 values\n",
    "                transmat[i, j] = hmm1['transmat'][i, j]\n",
    "            elif i < hmm1['transmat'].shape[0] - 1:  # Product of the last value of hmm1 and values of hmm2\n",
    "                transmat[i, j] = hmm1['transmat'][i, -1] * hmm2['startprob'][j - (hmm1['transmat'].shape[1] - 1)]\n",
    "            elif j >= hmm1['transmat'].shape[1] - 1:  # Copy of hmm2 values\n",
    "                transmat[i, j] = hmm2['transmat'][i - (hmm1['transmat'].shape[0] - 1),\n",
    "                                                  j - (hmm1['transmat'].shape[1] - 1)]\n",
    "    transmat[-1, -1] = 1  # Assign value 1 to the last transition\n",
    "\n",
    "    means = np.vstack((hmm1['means'], hmm2['means']))\n",
    "    covars = np.vstack((hmm1['covars'], hmm2['covars']))\n",
    "\n",
    "    concat_hmm['startprob'] = startprob\n",
    "    concat_hmm['transmat'] = transmat\n",
    "    concat_hmm['means'] = means\n",
    "    concat_hmm['covars'] = covars\n",
    "\n",
    "    return concat_hmm\n",
    "\n",
    "\n",
    "# this is already implemented, but based on concat2HMMs() above\n",
    "def concatHMMs(hmmmodels, namelist):\n",
    "    \"\"\" Concatenates HMM models in a left to right manner\n",
    "\n",
    "    Args:\n",
    "       hmmmodels: dictionary of models indexed by model name. \n",
    "       hmmmodels[name] is a dictionaries with the following keys:\n",
    "           - name: phonetic or word symbol corresponding to the model\n",
    "           - startprob: M+1 array with priori probability of state\n",
    "           - transmat: (M+1)x(M+1) transition matrix\n",
    "           - means: MxD array of mean vectors\n",
    "           - covars: MxD array of variances\n",
    "       namelist: list of model names that we want to concatenate\n",
    "\n",
    "    D is the dimension of the feature vectors\n",
    "    M is the number of emitting states in each HMM model (could be\n",
    "      different in each model)\n",
    "\n",
    "    Output\n",
    "       combinedhmm: dictionary with the same keys as the input but\n",
    "                    combined models:\n",
    "         startprob: K+1 array with priori probability of state\n",
    "          transmat: (K+1)x(K+1) transition matrix\n",
    "             means: KxD array of mean vectors\n",
    "            covars: KxD array of variances\n",
    "\n",
    "    K is the sum of the number of emitting states from the input models\n",
    "\n",
    "    Example:\n",
    "       wordHMMs['o'] = concatHMMs(phoneHMMs, ['sil', 'ow', 'sil'])\n",
    "    \"\"\"\n",
    "    concat = hmmmodels[namelist[0]]\n",
    "    for idx in range(1, len(namelist)):\n",
    "        concat = concatTwoHMMs(concat, hmmmodels[namelist[idx]])\n",
    "\n",
    "    return concat\n",
    "\n",
    "\n",
    "def gmmloglik(log_emlik, weights):\n",
    "    \"\"\"Log Likelihood for a GMM model based on Multivariate Normal Distribution.\n",
    "\n",
    "    Args:\n",
    "        log_emlik: array like, shape (N, K).\n",
    "            contains the log likelihoods for each of N observations and\n",
    "            each of K distributions\n",
    "        weights:   weight vector for the K components in the mixture\n",
    "\n",
    "    Output:\n",
    "        gmmloglik: scalar, log likelihood of data given the GMM model.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def forward(log_emlik, log_startprob, log_transmat):\n",
    "    \"\"\"Forward (alpha) probabilities in log domain.\n",
    "\n",
    "    Args:\n",
    "        log_emlik: NxM array of emission log likelihoods, N frames, M states\n",
    "        log_startprob: log probability to start in state i\n",
    "        log_transmat: log transition probability from state i to j\n",
    "\n",
    "    Output:\n",
    "        forward_prob: NxM array of forward log probabilities for each of the M states in the model\n",
    "    \"\"\"\n",
    "\n",
    "    forward_prob = np.zeros(log_emlik.shape)\n",
    "    forward_prob[0, :] = log_startprob[:-1] + log_emlik[0]  # Use all states but the last one --> ending state\n",
    "\n",
    "    for n in range(1, forward_prob.shape[0]):\n",
    "        for j in range(forward_prob.shape[1]):\n",
    "            forward_prob[n, j] = logsumexp(forward_prob[n - 1, :] + log_transmat[:-1, j]) + log_emlik[n, j]\n",
    "\n",
    "    return forward_prob\n",
    "\n",
    "\n",
    "def backward(log_emlik, log_transmat):\n",
    "    \"\"\"Backward (beta) probabilities in log domain.\n",
    "\n",
    "    Args:\n",
    "        log_emlik: NxM array of emission log likelihoods, N frames, M states\n",
    "        log_transmat: transition log probability from state i to j\n",
    "\n",
    "    Output:\n",
    "        backward_prob: NxM array of backward log probabilities for each of the M states in the model\n",
    "    \"\"\"\n",
    "\n",
    "    backward_prob = np.zeros(log_emlik.shape)\n",
    "\n",
    "    for n in reversed(range(backward_prob.shape[0] - 1)):\n",
    "        for i in range(backward_prob.shape[1]):\n",
    "            backward_prob[n, i] = logsumexp(log_transmat[i, :-1] + log_emlik[n + 1, :] + backward_prob[n + 1, :])\n",
    "\n",
    "    return backward_prob\n",
    "\n",
    "\n",
    "def viterbi(log_emlik, log_startprob, log_transmat, force_final_state=True):\n",
    "    \"\"\"Viterbi path.\n",
    "\n",
    "    Args:\n",
    "        log_emlik: NxM array of emission log likelihoods, N frames, M states\n",
    "        log_startprob: log probability to start in state i\n",
    "        log_transmat: transition log probability from state i to j\n",
    "        force_final_state: if True, start backtracking from the final state in\n",
    "                  the model, instead of the best state at the last time step\n",
    "\n",
    "    Output:\n",
    "        viterbi_loglik: log likelihood of the best path\n",
    "        viterbi_path: best path\n",
    "    \"\"\"\n",
    "\n",
    "    viterbi_loglik = np.zeros(log_emlik.shape)\n",
    "    viterbi_b_mat = np.zeros(log_emlik.shape, dtype=int)\n",
    "\n",
    "    viterbi_loglik[0] = log_startprob[:-1] + log_emlik[0]\n",
    "    for n in range(1, viterbi_loglik.shape[0]):\n",
    "        for j in range(viterbi_loglik.shape[1]):\n",
    "            viterbi_loglik[n, j] = np.max(viterbi_loglik[n - 1, :] + log_transmat[:-1, j]) + log_emlik[n, j]\n",
    "            viterbi_b_mat[n, j] = np.argmax(viterbi_loglik[n - 1, :] + log_transmat[:-1, j])\n",
    "\n",
    "    viterbi_path = [np.argmax(viterbi_b_mat[-1])]\n",
    "    for n in reversed(range(viterbi_b_mat.shape[0] - 1)):\n",
    "        viterbi_path.append(viterbi_b_mat[n, viterbi_path[-1]])\n",
    "    viterbi_path.reverse()\n",
    "\n",
    "    return np.max(viterbi_loglik[-1]), np.array(viterbi_path)\n",
    "\n",
    "\n",
    "def statePosteriors(log_alpha, log_beta):\n",
    "    \"\"\"State posterior (gamma) probabilities in log domain.\n",
    "\n",
    "    Args:\n",
    "        log_alpha: NxM array of log forward (alpha) probabilities\n",
    "        log_beta: NxM array of log backward (beta) probabilities\n",
    "    where N is the number of frames, and M the number of states\n",
    "\n",
    "    Output:\n",
    "        log_gamma: NxM array of gamma probabilities for each of the M states in the model\n",
    "    \"\"\"\n",
    "\n",
    "    log_gamma = log_alpha + log_beta - logsumexp(log_alpha[log_alpha.shape[0] - 1])\n",
    "\n",
    "    return log_gamma\n",
    "\n",
    "\n",
    "def updateMeanAndVar(x, log_gamma, variance_floor=5.0):\n",
    "    \"\"\" Update Gaussian parameters with diagonal covariance\n",
    "\n",
    "    Args:\n",
    "         x: NxD array of feature vectors\n",
    "         log_gamma: NxM state posterior probabilities in log domain\n",
    "         variance_floor: minimum allowed variance scalar\n",
    "    were N is the lenght of the observation sequence, D is the\n",
    "    dimensionality of the feature vectors and M is the number of\n",
    "    states in the model\n",
    "\n",
    "    Outputs:\n",
    "         means: MxD mean vectors for each state\n",
    "         covars: MxD covariance (variance) vectors for each state\n",
    "    \"\"\"\n",
    "\n",
    "    gamma = np.exp(log_gamma)\n",
    "\n",
    "    means = np.zeros((log_gamma.shape[1], x.shape[1]))\n",
    "    covars = np.zeros(means.shape)\n",
    "    for k in range(means.shape[0]):\n",
    "        means[k] = np.sum(gamma[:, k][:, np.newaxis] * x, axis=0) / np.sum(gamma[:, k])\n",
    "        covars[k] = np.sum(gamma[:, k][:, np.newaxis] * np.power(x - means[k], 2), axis=0) / np.sum(gamma[:, k])\n",
    "    covars[covars < variance_floor] = variance_floor  # Transform values below threshold\n",
    "\n",
    "    return means, covars\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Here starts the program main code:\n",
    "Load of the data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore')  # Suppress divide by zero warning\n",
    "example = np.load('lab2_example.npz', allow_pickle=True)['example'].item()\n",
    "phone_hmms = np.load('lab2_models_all.npz', allow_pickle=True)['phoneHMMs'].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " Concatenate all digit hmms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_hmms = {}\n",
    "for digit in prondict.keys():\n",
    "    word_hmms[digit] = concatHMMs(phone_hmms, ['sil'] + prondict[digit] + ['sil'])\n",
    "\n",
    "data = np.load('lab2_data.npz', allow_pickle=True)['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Forward algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the predictions has been: 97.73%\n"
     ]
    }
   ],
   "source": [
    "best_model = {}\n",
    "acc_count = 0\n",
    "for idx, dt in enumerate(data):  # Iterate over data samples\n",
    "    maxloglik = None\n",
    "    for digit in word_hmms.keys():  # Iterate over hmms\n",
    "        obsloglik = log_multivariate_normal_density_diag(dt['lmfcc'], word_hmms[digit]['means'],\n",
    "                                                         word_hmms[digit]['covars'])\n",
    "        logalpha = forward(obsloglik, np.log(word_hmms[digit]['startprob']),\n",
    "                           np.log(word_hmms[digit]['transmat']))\n",
    "        loglik = logsumexp(logalpha[-1])\n",
    "        if maxloglik is None or maxloglik < loglik:  # If better likelihood found\n",
    "            best_model[idx] = digit  # Set most probable model\n",
    "            maxloglik = loglik  # Update max log likelihood\n",
    "    if dt['digit'] == best_model[idx]:\n",
    "        acc_count += 1\n",
    "        \n",
    "print(\"The accuracy of the predictions has been: \" + str(np.round(acc_count / len(data) * 100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Viterbi algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the predictions has been: 100.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = {}\n",
    "acc_count = 0\n",
    "for idx, dt in enumerate(data):  # Iterate over data samples\n",
    "    maxloglik = None\n",
    "    for digit in word_hmms.keys():  # Iterate over hmms\n",
    "        obsloglik = log_multivariate_normal_density_diag(dt['lmfcc'], word_hmms[digit]['means'],\n",
    "                                                         word_hmms[digit]['covars'])\n",
    "        vloglik, vpath = viterbi(obsloglik, np.log(word_hmms[digit]['startprob']),\n",
    "                                 np.log(word_hmms[digit]['transmat']))\n",
    "        if maxloglik is None or maxloglik < vloglik:  # If better likelihood found\n",
    "            best_model[idx] = digit  # Set most probable model\n",
    "            maxloglik = vloglik  # Update max log likelihood\n",
    "    if dt['digit'] == best_model[idx]:\n",
    "        acc_count += 1\n",
    "    # print(\"The best model for utterance \" + str(idx) + \" was hmm: \" + str(best_model[idx]))\n",
    "    # print(\"The real digit of utterance \" + str(idx) + \" was digit: \" + str(dt['digit']) + \"\\n\")\n",
    "print(\"The accuracy of the predictions has been: \" + str(np.round(acc_count / len(data) * 100, 2)) + \"%\")\n",
    "\n",
    "logalpha = forward(example['obsloglik'], np.log(word_hmms['o']['startprob']), np.log(word_hmms['o']['transmat']))\n",
    "vloglik, vpath = viterbi(example['obsloglik'], np.log(word_hmms['o']['startprob']),\n",
    "                         np.log(word_hmms['o']['transmat']))\n",
    "plt.pcolormesh(logalpha.T)\n",
    "plt.plot(vpath.T, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Baum-Welch algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model o\n",
      "Log-likelihood: -6318.836143374649. Number of iterations until convergence: 5\n",
      "Trying model z\n",
      "Log-likelihood: -5833.2706240493735. Number of iterations until convergence: 5\n",
      "Trying model 1\n",
      "Log-likelihood: -5903.338261970016. Number of iterations until convergence: 10\n",
      "Trying model 2\n",
      "Log-likelihood: -6190.713363055122. Number of iterations until convergence: 5\n",
      "Trying model 3\n",
      "Log-likelihood: -6012.101687040113. Number of iterations until convergence: 4\n",
      "Trying model 4\n",
      "Log-likelihood: -5994.050816900842. Number of iterations until convergence: 5\n",
      "Trying model 5\n",
      "Log-likelihood: -5963.922425732666. Number of iterations until convergence: 5\n",
      "Trying model 6\n",
      "Log-likelihood: -5884.528943767897. Number of iterations until convergence: 5\n",
      "Trying model 7\n",
      "Log-likelihood: -5682.161964496241. Number of iterations until convergence: 5\n",
      "Trying model 8\n",
      "Log-likelihood: -6185.97163186002. Number of iterations until convergence: 4\n",
      "Trying model 9\n",
      "Log-likelihood: -5953.968391594907. Number of iterations until convergence: 5\n",
      "The best log-likelihood is: -5682.161964496241. It corresponds to the model 7\n"
     ]
    }
   ],
   "source": [
    "best_loglik = None\n",
    "best_model = None\n",
    "for digit in word_hmms.keys():  # Iterate over hmms\n",
    "    print(\"Trying model \" + str(digit))\n",
    "    means = word_hmms[digit]['means']\n",
    "    covars = word_hmms[digit]['covars']\n",
    "    obsloglik = log_multivariate_normal_density_diag(data[10]['lmfcc'], means, covars)\n",
    "    vloglik = 0\n",
    "    newloglik = viterbi(obsloglik, np.log(word_hmms[digit]['startprob']),\n",
    "                        np.log(word_hmms[digit]['transmat']))[0]\n",
    "    it = 0\n",
    "    while it < 20 and abs(newloglik - vloglik) > 1.0:\n",
    "        vloglik = newloglik  # Update value of log-likelihood\n",
    "        forward_prob = forward(obsloglik, np.log(word_hmms[digit]['startprob']),\n",
    "                               np.log(word_hmms[digit]['transmat']))\n",
    "        backward_prob = backward(obsloglik, np.log(word_hmms[digit]['transmat']))\n",
    "        log_gamma = statePosteriors(forward_prob, backward_prob)\n",
    "        means, covars = updateMeanAndVar(data[10]['lmfcc'], log_gamma)\n",
    "        obsloglik = log_multivariate_normal_density_diag(data[10]['lmfcc'], means, covars)\n",
    "        newloglik = viterbi(obsloglik, np.log(word_hmms[digit]['startprob']),\n",
    "                            np.log(word_hmms[digit]['transmat']))[0]\n",
    "        it += 1  # Update number of iterations\n",
    "    print(\"Log-likelihood: \" + str(newloglik) + \". Number of iterations until convergence: \" + str(it))\n",
    "    if best_loglik is None or newloglik > best_loglik:\n",
    "        best_loglik = newloglik\n",
    "        best_model = digit\n",
    "print(\"The best log-likelihood is: \" + str(best_loglik) + \". It corresponds to the model \" + str(best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
